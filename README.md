# Applied Deep Learning – Project Tasks

This repository contains a series of Jupyter notebooks demonstrating concepts and implementations in **Applied Deep Learning (ADL)**. Each notebook corresponds to a structured task focusing on different aspects of the machine learning pipeline – from data preprocessing to model optimization and evaluation.

The goal of this repository is to provide clear, reproducible implementations that highlight practical applications of deep learning techniques.

## Repository Contents

| Notebook | Description |
|----------|-------------|
| **`ADL_Task1.ipynb`** | Baseline experiment introducing the applied deep learning workflow. |
| **`Task_1.ipynb`** | Data preprocessing, exploratory data analysis (EDA), and simple model training. |
| **`Task_2.ipynb`** | Feature engineering, advanced preprocessing, and performance comparison. |
| **`Task3.ipynb`** | Neural network implementation with training/evaluation pipeline. |
| **`Task4.ipynb`** | Model optimization: regularization techniques, learning rate schedules, and hyperparameter tuning. |
| **`Task_5.ipynb`** | Final task: advanced evaluation metrics and deployment-oriented experiments. |

## Getting Started

### 1. Clone the Repository
```bash
git clone https://github.com/your-username/applied-deep-learning-tasks.git
cd applied-deep-learning-tasks
```

### 2. Create a Virtual Environment (recommended)
```bash
python -m venv venv
source venv/bin/activate   # On Mac/Linux
venv\Scripts\activate      # On Windows
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Run Jupyter Notebooks
```bash
jupyter lab
```
or
```bash
jupyter notebook
```

## Tech Stack

- **Programming Language**: Python 3.8+
- **Deep Learning Frameworks**: TensorFlow, PyTorch
- **Data Handling**: Pandas, NumPy
- **Visualization**: Matplotlib, Seaborn
- **ML Utilities**: Scikit-learn, Scikit-image

## Learning Outcomes

This project demonstrates:

- Preprocessing and preparing datasets for deep learning tasks
- Building and training neural network models
- Applying optimization strategies such as regularization and hyperparameter tuning
- Evaluating models with appropriate metrics
- Structuring experiments in a reproducible, modular way

## Notes

- Each notebook is self-contained and can be run independently
- GPU acceleration is recommended for faster training
- Results may vary slightly depending on random seeds and library versions

## License

This project is licensed under the **MIT License**. You are welcome to use, modify, and share the work with attribution.

---

⭐ If you like this project or find it useful, consider giving the repo a star on GitHub!
