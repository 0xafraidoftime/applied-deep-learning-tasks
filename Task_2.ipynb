{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 2**"
      ],
      "metadata": {
        "id": "AgvmVittsD5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics[image] torch-fidelity\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchmetrics.image.fid import FrechetInceptionDistance\n",
        "from torchmetrics.image.inception import InceptionScore\n",
        "import torchvision.utils as vutils\n",
        "import os\n",
        "\n",
        "# Spectral Normalization Generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias=False),  # Output: (512, 4, 4)\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),  # Output: (256, 8, 8)\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),  # Output: (128, 16, 16)\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(128, 3, 4, 2, 1, bias=False),  # Output: (3, 32, 32)\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "# Spectral Normalization Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.utils.spectral_norm(nn.Conv2d(3, 64, 4, 2, 1, bias=False)),  # Input: (3, 32, 32) -> Output: (64, 16, 16)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.utils.spectral_norm(nn.Conv2d(64, 128, 4, 2, 1, bias=False)),  # Output: (128, 8, 8)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.utils.spectral_norm(nn.Conv2d(128, 256, 4, 2, 1, bias=False)),  # Output: (256, 4, 4)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.utils.spectral_norm(nn.Conv2d(256, 512, 4, 2, 1, bias=False)),  # Output: (512, 2, 2)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Flatten(),  # Flatten to (512*2*2,)\n",
        "            nn.Linear(512 * 2 * 2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "def main():\n",
        "    # Hyperparameters\n",
        "    batch_size = 128\n",
        "    nz = 100  # Size of latent vector\n",
        "    lr = 0.0002\n",
        "    beta1 = 0.5\n",
        "    num_epochs = 5\n",
        "\n",
        "    # Create directory for saving images\n",
        "    os.makedirs(\"sngan_generated_images\", exist_ok=True)\n",
        "\n",
        "    # Initialize FID and IS\n",
        "    fid = FrechetInceptionDistance(normalize=True).to(\"cpu\")\n",
        "    inception = InceptionScore().to(\"cpu\")\n",
        "\n",
        "    # DataLoader for CIFAR-10\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(32),  # Resize images to 32x32\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))  # Normalize images between -1 and 1\n",
        "    ])\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        datasets.CIFAR10('./data', download=True, transform=transform),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    netG = Generator().to(device)\n",
        "    netD = Discriminator().to(device)\n",
        "\n",
        "    optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "    optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    fixed_noise = torch.randn(25, nz, 1, 1, device=device)  # Fixed noise for generating 25 images\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, data in enumerate(dataloader, 0):\n",
        "            # Update Discriminator\n",
        "            netD.zero_grad()\n",
        "            real_cpu, _ = data\n",
        "            real_cpu = real_cpu.to(device)\n",
        "\n",
        "            batch_size = real_cpu.size(0)\n",
        "            real_label = torch.full((batch_size, 1), 1.0, dtype=torch.float, device=device)\n",
        "            fake_label = torch.full((batch_size, 1), 0.0, dtype=torch.float, device=device)\n",
        "\n",
        "            output = netD(real_cpu)\n",
        "            errD_real = criterion(output, real_label)\n",
        "            errD_real.backward()\n",
        "\n",
        "            noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
        "            fake = netG(noise)\n",
        "            output = netD(fake.detach())\n",
        "            errD_fake = criterion(output, fake_label)\n",
        "            errD_fake.backward()\n",
        "            optimizerD.step()\n",
        "\n",
        "            # Update Generator\n",
        "            netG.zero_grad()\n",
        "            output = netD(fake)\n",
        "            errG = criterion(output, real_label)\n",
        "            errG.backward()\n",
        "            optimizerG.step()\n",
        "\n",
        "            # Print training stats\n",
        "            if i % 100 == 0:\n",
        "                print(f'Epoch [{epoch+1}/{num_epochs}] | Batch [{i+1}/{len(dataloader)}] | '\n",
        "                      f'D Loss: {errD_real.item() + errD_fake.item()} | G Loss: {errG.item()}')\n",
        "\n",
        "        # Save 25 images at the end of each epoch\n",
        "        with torch.no_grad():\n",
        "            fake_images = netG(fixed_noise).detach().cpu()\n",
        "        vutils.save_image(fake_images, f\"sngan_generated_images/epoch_{epoch+1}.png\", normalize=True, nrow=5)\n",
        "\n",
        "        # Compute FID and IS after each epoch\n",
        "        real_cpu_norm = (real_cpu + 1) / 2.0\n",
        "        fake_norm = (fake + 1) / 2.0\n",
        "\n",
        "        real_cpu_uint8 = (real_cpu_norm * 255).clamp(0, 255).to(torch.uint8)\n",
        "        fake_uint8 = (fake_norm * 255).clamp(0, 255).to(torch.uint8)\n",
        "\n",
        "        fid.update(real_cpu_uint8, real=True)\n",
        "        fid.update(fake_uint8, real=False)\n",
        "        inception.update(fake_uint8)\n",
        "\n",
        "        fid_score = fid.compute()\n",
        "        inception_score = inception.compute()\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}] - FID Score: {fid_score.item()}, Inception Score: {inception_score[0].item()}')\n",
        "\n",
        "        # Reset FID and IS metrics after each epoch\n",
        "        fid.reset()\n",
        "        inception.reset()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "TOOat_JpkCE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f849cb5-08c9-4aa4-c10e-400feea59980"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch-fidelity\n",
            "  Downloading torch_fidelity-0.3.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting torchmetrics[image]\n",
            "  Downloading torchmetrics-1.4.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics[image]) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics[image]) (24.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics[image]) (2.4.0+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics[image])\n",
            "  Downloading lightning_utilities-0.11.7-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: torchvision>=0.8 in /usr/local/lib/python3.10/dist-packages (from torchmetrics[image]) (0.19.0+cu121)\n",
            "Requirement already satisfied: scipy>1.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics[image]) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from torch-fidelity) (9.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-fidelity) (4.66.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics[image]) (71.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics[image]) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics[image]) (3.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics[image]) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics[image]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics[image]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics[image]) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics[image]) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics[image]) (1.3.0)\n",
            "Downloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\n",
            "Downloading lightning_utilities-0.11.7-py3-none-any.whl (26 kB)\n",
            "Downloading torchmetrics-1.4.2-py3-none-any.whl (869 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.2/869.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, torch-fidelity\n",
            "Successfully installed lightning-utilities-0.11.7 torch-fidelity-0.3.0 torchmetrics-1.4.2\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/toshas/torch-fidelity/releases/download/v0.2.0/weights-inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/weights-inception-2015-12-05-6726825d.pth\n",
            "100%|██████████| 91.2M/91.2M [00:00<00:00, 409MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `InceptionScore` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 83770407.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Epoch [1/5] | Batch [1/391] | D Loss: 1.3933030366897583 | G Loss: 0.7236005067825317\n",
            "Epoch [1/5] | Batch [101/391] | D Loss: 0.8858745396137238 | G Loss: 1.714690923690796\n",
            "Epoch [1/5] | Batch [201/391] | D Loss: 0.9719308018684387 | G Loss: 1.0440354347229004\n",
            "Epoch [1/5] | Batch [301/391] | D Loss: 1.2604663968086243 | G Loss: 0.6766989827156067\n",
            "Epoch [1/5] - FID Score: 364.4429931640625, Inception Score: 2.208373785018921\n",
            "Epoch [2/5] | Batch [1/391] | D Loss: 1.23647540807724 | G Loss: 0.9379602074623108\n",
            "Epoch [2/5] | Batch [101/391] | D Loss: 1.2632673978805542 | G Loss: 0.7409140467643738\n",
            "Epoch [2/5] | Batch [201/391] | D Loss: 1.353330135345459 | G Loss: 0.8858590722084045\n",
            "Epoch [2/5] | Batch [301/391] | D Loss: 1.3169527053833008 | G Loss: 0.858943521976471\n",
            "Epoch [2/5] - FID Score: 334.59283447265625, Inception Score: 2.0675463676452637\n",
            "Epoch [3/5] | Batch [1/391] | D Loss: 1.328259527683258 | G Loss: 0.8953539133071899\n",
            "Epoch [3/5] | Batch [101/391] | D Loss: 1.3729501366615295 | G Loss: 0.8339219093322754\n",
            "Epoch [3/5] | Batch [201/391] | D Loss: 1.3646813035011292 | G Loss: 0.7568386793136597\n",
            "Epoch [3/5] | Batch [301/391] | D Loss: 1.3890430927276611 | G Loss: 0.9982470273971558\n",
            "Epoch [3/5] - FID Score: 327.933837890625, Inception Score: 2.1511285305023193\n",
            "Epoch [4/5] | Batch [1/391] | D Loss: 1.2289749383926392 | G Loss: 0.7862018942832947\n",
            "Epoch [4/5] | Batch [101/391] | D Loss: 1.1546190977096558 | G Loss: 0.9169279336929321\n",
            "Epoch [4/5] | Batch [201/391] | D Loss: 1.1154211163520813 | G Loss: 0.832829475402832\n",
            "Epoch [4/5] | Batch [301/391] | D Loss: 1.199483573436737 | G Loss: 0.9503293633460999\n",
            "Epoch [4/5] - FID Score: 344.1303405761719, Inception Score: 2.188511848449707\n",
            "Epoch [5/5] | Batch [1/391] | D Loss: 1.1252990067005157 | G Loss: 1.0036261081695557\n",
            "Epoch [5/5] | Batch [101/391] | D Loss: 1.0347811579704285 | G Loss: 1.2496256828308105\n",
            "Epoch [5/5] | Batch [201/391] | D Loss: 1.0824021399021149 | G Loss: 1.115340232849121\n",
            "Epoch [5/5] | Batch [301/391] | D Loss: 1.1782124042510986 | G Loss: 0.907591700553894\n",
            "Epoch [5/5] - FID Score: 324.25592041015625, Inception Score: 1.8818871974945068\n"
          ]
        }
      ]
    }
  ]
}